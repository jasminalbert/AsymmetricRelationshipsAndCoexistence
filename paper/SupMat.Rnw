\documentclass[letterpaper,11pt]{article}

%packages
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage[left=2cm,top=2cm,right=2cm,bottom=2cm,head=.5cm,foot=.5cm]{geometry}
\usepackage{url}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{subfig}
\usepackage{float}
\usepackage{setspace}
\usepackage{lineno}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{xr}
\usepackage{authblk}
\usepackage{mathrsfs}
\usepackage{relsize}
\usepackage{tikz}
\usepackage{accents}

\setcounter{figure}{0}
\renewcommand{\thefigure}{S\arabic{figure}}
\setcounter{table}{0}
\renewcommand{\thetable}{S\arabic{table}}
\setcounter{section}{0}
\renewcommand{\thesection}{S\arabic{section}}

%new commands and so on
\DeclareRobustCommand{\bbone}{\text{\usefont{U}{bbold}{m}{n}1}}

\DeclareMathOperator{\E}{\mathbb{E}}% expected value
\DeclareMathOperator{\VarX}{var}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\CovX}{cov}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\Prob}{P}
\DeclareMathOperator{\rk}{rank}
\DeclareMathOperator{\nrk}{nrank}

\newcommand{\sC}{\mathscr{C}} %for a script C like Ellner et al (2016), Ecol Lett
\newcommand{\bs}{\backslash}

%attempt 3 at nat and sharp (see Paper.Rnw for attempts 1 and 2, which I decided not to use)
\newcommand{\nat}{%
\text{\hspace{-1.5pt}
\begin{tikzpicture}[scale=1.8]%
\draw (.333ex,0) -- (.333ex,1ex);%
\draw (.666ex,0) -- (.666ex,1ex);
\end{tikzpicture}%
}}
\newcommand{\shp}{%
\text{\hspace{-1.5pt}
\begin{tikzpicture}[scale=1.8]%
\draw (0,.333ex) -- (1ex,.333ex);%
\draw (0,.666ex) -- (1ex,.666ex);%
\draw (.333ex,0) -- (.333ex,1ex);%
\draw (.666ex,0) -- (.666ex,1ex);
\end{tikzpicture}%
}}
\newcommand{\test}{%
\text{
\begin{tikzpicture}[scale=1.8]%
\draw (0,0) -- (1ex,0ex);
\draw (0,0) -- (0ex,1ex);
\draw (0,1ex) -- (1ex,1ex);
\draw (1ex,0) -- (1ex,1ex);
\draw (0,.333ex) -- (2ex,.333ex);%
\draw (0,.666ex) -- (1ex,.666ex);%
\draw (.333ex,0) -- (.333ex,1ex);%
\draw (.666ex,0) -- (.666ex,1ex);
\end{tikzpicture}%
}}

\newcommand{\olr}{\overline{r}}
\newcommand{\olrs}{\overline{r}^{\shp}}
\newcommand{\olrn}{\overline{r}^{\nat}}
\newcommand{\olep}{\overline{\epsilon}}
\newcommand{\olE}{\overline{E}}
\newcommand{\olC}{\overline{C}}

%external documents
\externaldocument[MT-]{Paper}

%header material for paper
\title{Asymmetric relationships and their effects on coexistence: Supporting information}
\date{}

\author[a]{Pimsupa Jasmin Albert}
\author[a,b,*]{Daniel C. Reuman}

\affil[a]{Department of Ecology and Evolutionary Biology and Center for Ecological Research, University of Kansas}
\affil[b]{Laboratory of Populations, Rockefeller University}
\affil[*]{Corresponding author, reuman@ku.edu}

%for dealing with line numbers bugs having to do with equations
\let\oldequation\equation
\let\oldendequation\endequation
\renewenvironment{equation}
  {\linenomathNonumbers\oldequation}
  {\oldendequation\endlinenomath}
\let\oldalign\align
\let\oldendalign\endalign
\renewenvironment{align}
  {\linenomathNonumbers\oldalign}
  {\oldendalign\endlinenomath}

\begin{document}
\SweaveOpts{concordance=TRUE}

%The following is where you load in the numeric results that will be embedded in the text
<<eval=T,echo=F,message=F,warning=F>>=
#system(paste("biber", sub("\\.Rnw$", "", current_input())))

#place R code here for loading in necessary variables from Results
#ordinarily this would be a readRDS command, but I'm just defining a variable here for now
#allregres<-matrix(rnorm(10),2,5)
M <- readRDS(file="../results_numeric/M.RDS")
rho <- readRDS(file="../results_numeric/rho.RDS")
se3qij <- readRDS(file="../results_numeric/fig3qijmaxse.RDS")
se4qij <- readRDS(file="../results_numeric/fig4qijmaxse.RDS")
@

\linenumbers
\maketitle

\tableofcontents
\listoffigures

\section{Scaling factors}\label{SIsect:scaling_factors}

Following \cite{Ellner_2016}, we define
\begin{equation}
\sC_j = -r_j(\overline{E}_j,C_j),
\end{equation}
and 
\begin{equation}
\sC_{j \bs i} = -r_j(\overline{E}_j,C_{j \bs i}),
\end{equation}
i.e., $\sC_{j \bs i}$ is the negative of the growth rate of species $j$ when $E_j$ is at its mean value
and when $i$ is at negligible abundance. Then $q_{ij}$ is defined by computing
\begin{equation}
\frac{\partial \sC_{i \bs i}}{\partial \sC_{j \bs i}},
\end{equation}
and evaluating it at $\sC_{j \bs i}=0$ [see \cite{Chesson_1994} and \cite{Ellner_2016} for background
on this definition]. To make sense of this definition, it must be possible to write $\sC_{i \bs i}$, explicitly 
or implicitly, uniquely as a function of $\sC_{j \bs i}$ \citep{Ellner_2016}.

We also use $q_{ij}=1$ as an alternative value, for the following reasons.
First, as discussed in the supporting information of \cite{Ellner_2016}, and as further elaborated by 
\cite{Barabas_2018}, it takes very special circumstances for the scaling factors to exist and be unique, 
especially with size-structured models. Second, in empirically parameterized models, scaling factor values are 
often not robust to arbitrary modelling choices. 
Although the lottery model to which we apply our theory 
is not size structured and we do not empirically parameterize it, the above shortcomings of 
scaling factors, generally, suggest we should find alternatives to their use. The alternative 
suggested by Ellner for empirical applications is to do a series of pairwise invader-resident comparisons, each with an 
equal weighting of invader and resident $r$ values; for our context this amounts to setting scaling factors to $1$. 
We consider both approaches because the above-mentioned shortcomings do not apply to our case, but it seems 
possible that future applications will often set scaling factors to $1$, and we want our ideas to also be considered 
by researchers making that choice. 

\section{Removing asymmetries of association}\label{sect:remove_asymmetries}

How are asymmetries of tail association removed while leaving $E$ and $C$ marginal distributions and overall 
correlation unchanged? Fig. \ref{fig:pedagog2} provides an illustration of the steps we describe here. 
We assume, for simplicity, that the cumulative distribution functions (CDFs) of $E_i$ and 
$C_{i \bs i}$, which we denote $F_{E_i}$ and $F_{C_{i \bs i}}$, respectively, are strictly monotonic and continuous. 
Letting $\varphi$ be the CDF of a standard normal distribution, we consider the random variables
$\varphi^{-1} \circ F_{E_i} (E_i)$ and $\varphi^{-1} \circ F_{C_{i \bs i}}(C_{i \bs i})$, which are standard normally
distributed, although they are not necessarily jointly bivariate normal (Fig. \ref{fig:pedagog2}a,b).  
Let $\rho_i$ be the covariance of
these random variables. We then define a bivariate normal random variable $(e_i,c_{i \bs i})$ such that
$\E(e_i)=\E(c_{i \bs i})=0$ and $\var(e_i)=\var(c_{i \bs i})=1$, and we denote 
$\cov(e_i,c_{i \bs i})$ by $\ddot{\rho}_i$ (Fig. \ref{fig:pedagog2}c). We define 
$E_i^\nat = F_{E_i}^{-1} \circ \varphi(e_i)$
and $C_{i \bs i}^\nat=F_{C_{i \bs i}}^{-1} \circ \varphi(c_{i \bs i})$ (Fig. \ref{fig:pedagog2}d). 
The value of $\ddot{\rho}_i$ is then determined in one of 
four alternative ways: either by setting $\ddot{\rho}_i = \rho_i$; or so that the Pearson, Spearman or Kendall correlation of 
$E_i^\nat$ and $C_{i \bs i}^\nat$ matches that of $E_i$ and $C_{i \bs i}$. The choice of bivariate normal 
$(e_i,c_{i \bs i})$ ensures that $E_i^\nat$ and $C_{i \bs i}^\nat$ are symmetrically tail associated.
For those familiar with copula statistics (see, e.g., \citealp{Genest_2007} and \citealp{Ghosh_2020_AER}), 
we replaced the copula of $(E_i,C_{i \bs i})$ with a normal copula to form $(E_i^\nat,C_{i \bs i}^\nat)$.
The choice of $\ddot{\rho}_i$ ensures that $E_i^\nat$ and $C_{i \bs i}^\nat$ are correlated to the same extent as 
$E_i$ and $C_{i \bs i}$, according to whichever definition of correlation is considered preferable. Thus $E_i^\nat$ and 
$C_{i \bs i}^\nat$ have had their tail association rendered symmetric while retaining their correlation \emph{per se},
as desired. The random variable $(E_j^\nat, C_{j \bs i}^\nat)$ is created similarly.  

\section{Mechanisms other than storage effects}\label{SIsect:other_mechanisms}

We first review the decompositions of \cite{Ellner_2016} and \cite{Ellner_2019}, which are similar to and motivated by the 
original decompositions of \cite{Chesson_1994}; and then we include our extension of the decomposition. 

We begin by decomposing the GWR,
\begin{equation}
\olr_{i \bs i}=\E[r_i(E_i,C_{i \bs i})].
\end{equation}
Replacing both $E_i$ and $C_{i \bs i}$ with their means gives 
\begin{align}
\epsilon_i^0 = r_i(\overline{E}_i,\overline{C}_{i \bs i}).
\end{align}
The additional contribution of variation in $E_i$ to the GWR is then
\begin{equation}
\olep_i^E = \E[r_i(E_i,\overline{C}_{i \bs i})]-\epsilon_i^0,
\end{equation}
whereas the additional contribution of variation in $C_{i \bs i}$ is 
\begin{equation}
\olep_i^C=\E[r_i(\overline{E}_i,C_{i \bs i})]-\epsilon_i^0.
\end{equation}
We then define
\begin{align}
\olep_i^{EC} &= \E[r_i(E_i,C_{i \bs i})]-\olep_i^E-\olep_i^C-\epsilon_i^0 \\
&= \olr_{i \bs i} - \olep_i^E - \olep_i^C - \epsilon_i^0.
\end{align}
Thus we have the primary decomposition 
\begin{equation}
\olr_{i \bs i} = \epsilon_i^0 + \olep_i^E + \olep_i^C + \olep_i^{EC}.
\end{equation}
But some of $\olep_i^{EC}$ comes from the fact that $E_i$ and $C_{i \bs i}$ are
both varying, and some comes from covariation in these two quantities. So we next separate these
contributions in a secondary decomposition of $\olep_i^{EC}$. 

Let
\begin{equation}
\olep_i^{(E\shp C)}=\E[r_i(E_i^\shp,C^\shp_{i \bs i})]-\olep_i^E-\olep_i^C-\epsilon_i^0
\end{equation}
and let
\begin{equation}
\olep_i^{(EC)} = \olep_i^{EC}-\olep_i^{(E\shp C)},
\end{equation}
so
\begin{equation}
\olep_i^{(EC)}=\E[r_i(E_i,C_{i \bs i})]-\E[r_i(E_i^\shp,C_{i \bs i}^\shp)].
\end{equation}
The parentheses in the superscripts of $\olep_i^{(EC)}$ and $\olep_i^{(E\shp C)}$
indicate that we are talking about a term in the secondary decomposition, i.e., in the decomposition of 
$\olep_i^{EC}$. We now have
\begin{align}
\olr_{i \bs i} &= \epsilon_i^0 + \olep_i^E + \olep_i^C + \olep_i^{EC} \\
\olep_i^{EC} &= \olep_i^{(E\shp C)}+\olep_i^{(EC)},
\end{align}
i.e.,
\begin{equation}
\olr_{i \bs i} = \epsilon_i^0 + \olep_i^E + \olep_i^C +\olep_i^{(E\shp C)}+\olep_i^{(EC)}. 
\end{equation}
The term $\olep_i^{(EC)}$ is due to covariation between $E_i$ and $C_{i \bs i}$, whereas the term 
$\olep_i^{(E\shp C)}$ is due to variation \emph{per se} in both $E_i$ and $C_{i \bs i}$, after the effects of 
covariation itself are removed. 
The term $\olep_i^{(EC)}$ relates to storage effects, as we will see. 

As in the main text, we can now define the tertiary decomposition
\begin{align}
\olep_i^{(EC)} &= \E[r_i(E_i,C_{i \bs i})]-\E[r_i(E_i^\shp,C_{i \bs i}^\shp)] \\
&= \left[ \E[r_i(E_i,C_{i \bs i})]-\E[r_i(E_i^\nat,C_{i \bs i}^\nat)] \right]+\left[ \E[r_i(E_i^\nat,C_{i \bs i}^\nat)]-\E[r_i(E_i^\shp,C_{i \bs i}^\shp)] \right] \\
&= \olep_i^{[EC]}+\olep_i^{[E \nat C]}.
\end{align}
The brackets in the superscripts of $\olep_i^{[EC]}$ and $\olep_i^{[E \nat C]}$ indicate that we are talking about a term in the
tertiary decomposition, i.e., in the decomposition of $\olep_i^{(EC)}$. 
The term $\olep_i^{[EC]}$ quantifies the influence of asymmetric tail associations of $E_i$ and $C_{i \bs i}$ on GWR,
and the the term $\olep_i^{[E \nat C]}$ corresponds to $EC$ correlations \emph{per se}, after the removal of asymmetries of tail association.
The symbol $\nat$ denotes the removal of asymmetries of tail association. We therefore have 
\begin{equation}
\olr_{i \bs i} = \epsilon_i^0 + \olep_i^E + \olep_i^C + \olep_i^{(E\shp C)}+\olep_i^{[E \nat C]}+\olep_i^{[EC]},\label{eq:decomp_overall_IGR}
\end{equation}
our overall decompsition of $r_{i \bs i}$.
The same derivation also applies to provide 
\begin{equation}
\olr_{j \bs i} = \epsilon_j^0 + \olep_j^E + \olep_j^C + \olep_j^{(E\shp C)}+\olep_j^{[E \nat C]}+\olep_j^{[EC]},\label{eq:decomp_overall_rjbsi}
\end{equation}
an analogous decomposition of $\olr_{j \bs i}$.

Combining the decompositions of $\olr_{i \bs i}$ and $\olr_{j \bs i}$, we have
\begin{equation}
\olr_{i \bs i}-q_{ij}\olr_{j \bs i}=\Delta_i^0+\Delta_i^E+\Delta_i^C+\Delta_i^{(E\shp C)}+\Delta_i^{[E \nat C]}+\Delta_i^{[EC]},\label{eq:decomp_overall_delta}
\end{equation}
where $\Delta_i^0=\epsilon_i^0- q_{ij} \epsilon_j^0$;
$\Delta_i^E=\olep_i^E -q_{ij}\olep_j^E$ is the contribution to coexistence of environmental variation;
$\Delta_i^C=\olep_i^C -q_{ij}\olep_j^C$ is the contribution to coexistence of variation in competitive pressure;
$\Delta_i^{(E\shp C)}=\olep_i^{(E\shp C)} - q_{ij}\olep_j^{(E\shp C)}$ is the contribution to coexistence of 
variation \emph{per se} in both environment and competition, not including the effects of covariation of these quantities;
 $\Delta_i^{[E\nat C]}=\olep_i^{[E \nat C]}-q_{ij} \olep_j^{[E \nat C]}$is the contribution to coexistence of $EC$ covariation \emph{per se},
not including the effects of asymmetric tail associations between environment and competition;
and $\Delta_i^{[EC]}=\olep_i^{[EC]} - q_{ij} \olep_j^{[EC]}$ is the contribution to coexistence of 
asymmetric tail associations. The subscript $i$ on all these newly defined quantities $\Delta_i$ refers to species $i$.

\section{Noise} \label{sect:noise}

To generate $M$ points $\left(b_1^{(i)}, b_2^{(i)}\right)$, $i=1,..,M$, for the left-tail association 
case (Fig. \ref{MT-fig:pedagog1}a), we first generated M points $(a_1^{(i)},a_2^{(i)})$, $i=1,...,M$, from a bivariate normal 
distribution $N\left( \vec{0}, \Sigma \right)$, where $\Sigma = \begin{pmatrix} 1&0\\0&1\end{pmatrix}$. 
Then, for each index $i$, we randomly, with 50\% probability, either 
(A) let $b_1^{(i)} = -|a_1^{(i)}|$ and $b_2^{(i)} = -|a_1^{(i)}|$, or 
(B) let $b_1^{(i)} = |a_1^{(i)}|$ and $b_2^{(i)} = |a_2^{(i)}|$. 
Perfect association in the left tails of the resulting distribution $\left(b_1,b_2\right)$ results from 
the fact that, in case (A) above, both $b_1^{(i)}$ and $b_2^{(i)}$ were assigned to the same value. 
Right-tail associated noise (Fig. \ref{MT-fig:pedagog1}c) was generated in an analogous way. 

When needed, noise with symmetric tail association (Fig. \ref{MT-fig:pedagog1}b) was generated by taking a 
very large sample (\Sexpr{M}) 
of left-tail associated noise generated as 
described above, and then calculating the Pearson correaltion coefficient, 
$\rho$, of the sample.
Symmetric noise $\left(b_1^{(i)},b_2^{(i)}\right)$ for $i=1,...,M$ was then 
generated 
from the bivariate normal distribution $N\left(\vec{0}, \Sigma \right)$, where now
$\Sigma = \begin{pmatrix} 1&\rho \\ \rho&1\end{pmatrix}$.

\section{Theory for the lottery model}\label{SIsect:TheoryForLottery}

\subsection{Theory that applies to both versions of the model}\label{SIsect:TheoryForLotteryBoth}

Recall we took $E_i(t)=B_i(t)$, thereby assuming that fecundity depends strictly on
the environment for the lottery model (both the log-normal fecundities and the beta fecundities versions of the model). 
Recall also that competition, $C_i(t)$, is 
\begin{equation}
C_i(t)=( B_1(t)N_1(t)+B_2(t)N_2(t) )/(\delta N)
\end{equation}
(again for both versions of the model), which
does not depend on $i$. Species growth rates for the lottery model, $r_i(t)=\ln(N_{i}(t+1)/N_i(t))$, can then be written 
\begin{equation}
r_i(t)=\ln[1-\delta+\delta N B_i(t)/(B_1(t)N_1(t)+B_2(t)N_2(t))]=\ln[1-\delta+E_i(t)/C_i(t)],
\end{equation}
which is an increasing
function of $E_i$ and decreasing function of $C_i$, as was assumed at the outset of Theory.

When $i$ is an invader, the competition experienced by either 
species is obtained from the expression for $C_i=C_j$ by setting $N_i=0$ and $N_j=N$. Thus 
\begin{equation}
C_{i \bs i}(t)=C_{j \bs i}(t)=B_j(t)/\delta=E_j(t)/\delta.
\end{equation}
Lottery-model values of all the expressions of SI section \ref{SIsect:other_mechanisms} can be obtained 
from the above expression for $C_{i \bs i}$ and the assumption that $E_i(t)=B_i(t)$.
For instance, 
\begin{equation}
\olr_{i \bs i} = \E[r_i(E_i,C_{i \bs i})] = \E[\ln(1-\delta+E_i /C_{i \bs i})] = \E[\ln(1-\delta+\delta B_i/B_j)].
\end{equation}
Likewise, 
\begin{equation}
\olr_{j \bs i} = \E[r_j(E_j,C_{j \bs i})] = \E[\ln(1-\delta+E_j/C_{j \bs i})] = \E[\ln(1-\delta+\delta B_j/B_j)]=0,
\end{equation}
though we already knew, \emph{a priori}, that this equals $0$. 
An expression for $\olrs_{i \bs i}$ is obtained by replacing $(E_i,C_{i \bs i})=(B_i,B_j/\delta)$
by a random variable with the same marginals, but independent components, $(B_i^\shp,B_j^\shp /\delta)$.
Thus 
\begin{equation}
\olrs_{i \bs i} = \E[\ln(1-\delta+\delta B_i^\shp/B_j^\shp)].
\end{equation}
Likewise, $\olrs_{j \bs i}$ is computed by replacing $(E_j,C_{j \bs i})$ in an analogous way; we can use 
$(E_j^\shp,C_{j \bs i}^\shp)=(B_j^\shp, B_j /\delta)$, so 
\begin{equation}
\olrs_{j \bs i}=\E[\ln(1-\delta+\delta B_j^\shp / B_j)].
\end{equation}
An expression for $\olrn_{i \bs i}$ is obtained by replacing $(E_i,C_{i \bs i})=(B_i,B_j/\delta)$
by a random variable with the same marginals, but with ATAs removed, $(B_i^\nat,B_j^\nat /\delta)$.
Thus 
\begin{equation}
\olrn_{i \bs i} = \E[\ln(1-\delta+\delta B_i^\nat/B_j^\nat)].
\end{equation}
Likewise, $\olrn_{j \bs i}$ is computed by replacing $(E_j,C_{j \bs i})=(B_j,B_j/\delta)$ in an analogous way.
But note that $B_j$ and $B_j/\delta$ are linearly related for the lottery model, so their association is 
already symmetric, so
so $E_j^\nat=E_j$, $C_{j \bs i}^\nat = C_{j \bs i}$, and $\olrn_{j \bs i}=\olr_{j \bs i}$.
This type of reasoning is applied to the log-normal fecundities and beta fecundities versions of the 
lottery model, specifically, in the subsequent sections. 

%scaling factors
We now consider the scaling factors $q_{ij}$ for the lottery model. 
For the lottery model, for $i \neq j$, we have
\begin{align}
\sC_j &= -\ln \left[ 1-\delta+\delta N \frac{\overline{B}_j}{B_1(t) N_1 (t) + B_2(t) N_2(t)}  \right]  \\
\sC_{j \bs i} &= -\ln \left[ 1-\delta+\delta  \frac{\overline{B}_j}{B_j(t)} \right] \\
\sC_{i \bs i} &= -\ln \left[ 1-\delta+\delta  \frac{\overline{B}_i}{B_j(t)} \right].
\end{align}
Both $\sC_{i \bs i}$ and $\sC_{j \bs i}$ are strictly monotonic functions of $B_j$, so the function
$B_j \mapsto \sC_{j \bs i}$ is invertible, and using its inverse provides an expression of $\sC_{i \bs i}$
in terms of $\sC_{j \bs i}$. One could write this expression explicitly and then differentiate it to calculate $q_{ij}$,
but we instead compute $q_{ij}$ through implicit differentiation:
\begin{align}
\frac{\partial \sC_{i \bs i}}{\partial \sC_{j \bs i}} &= \left. \frac{\partial \sC_{i \bs i}}{\partial B_j} \middle/ \frac{\partial \sC_{j \bs i}}{\partial B_j} \right. \\
&= \left( \frac{1-\delta +\delta \frac{\overline{B}_j}{B_j}}{1-\delta+\delta \frac{\overline{B}_i}{B_j}} \right) \left( \frac{\overline{B}_i}{\overline{B}_j}  \right).
\end{align}
Solving $\sC_{j \bs i}=0$ gives $B_j=\overline{B}_j$, so
\begin{align}
q_{ij} &= \left( \frac{1-\delta +\delta \frac{\overline{B}_j}{\overline{B}_j}}{1-\delta+\delta \frac{\overline{B}_i}{\overline{B}_j}} \right) \left( \frac{\overline{B}_i}{\overline{B}_j}  \right) \\
&= \frac{\overline{B}_i}{\overline{B}_j (1-\delta) +\overline{B}_i \delta}.
\end{align}
This expression is made specific to the log-normal decundities and beta fecundities versions of the lottery
model in the subsequent sections. We alternatively also consider $q_{ij}=1$, for reasons explained in SI 
section \ref{SIsect:scaling_factors}.

\subsection{Theory and plotting simplifications for the log-normal fecundities lottery model}\label{SIsect:TheoryForLotteryLogNorm}

%The first of the two growth rate decompositions
We first compute all terms of the decomposition (\ref{eq:decomp_overall_IGR}) of $\olr_{i \bs i}$ for the 
log-normal fecundities lottery model. 
One can straightforwardly show from the formulas of SI section \ref{SIsect:other_mechanisms} that
\begin{equation}
E_i=B_i=\exp(\sigma b_i +\mu_i)
\end{equation}
\begin{equation}
C_{i \bs i} = B_j/\delta=\exp(\sigma b_j + \mu_j)/\delta
\end{equation}
%IGR
\begin{align}
\olr_{i \bs i} &= \E[\ln(1-\delta+\delta B_i/B_j)] \\
&= \E[\ln(1-\delta+\delta\exp(\sigma(b_i-b_j)+\mu_i-\mu_j))]\label{eq:base_IGR}
\end{align}
\begin{equation}
\overline{E}_i = \exp(\mu_i + \sigma^2/2)
\end{equation}
\begin{equation}
\overline{C}_{i \bs i}=\exp(\mu_j+\sigma^2/2)/\delta
\end{equation}
%baseline
\begin{equation}
\epsilon_i^0 = \ln(1-\delta+\delta \exp(\mu_i - \mu_j))\label{eq:decomp:baseline}
\end{equation}
%contrib of variation in E
and
\begin{align}
\olep_i^E &= \E[\ln(1-\delta+\delta\exp(\sigma b_i + \mu_i)/\exp(\mu_j + \sigma^2/2))]-\epsilon_i^0 \\
&= \E[\ln(1-\delta+\delta\exp(\sigma b_i + \mu_i - \mu_j - \sigma^2/2))]-\epsilon_i^0, \label{eq:decomp:contrib_of_var_E}
\end{align}
where $b_i$ is standard normally distributed (see SI section \ref{sect:noise}). Continuing,
%contrib of variation in C
\begin{align}
\olep_i^C &= \E[\ln(1-\delta + \delta \exp(\mu_i+\sigma^2/2)/\exp(\sigma b_j + \mu_j))]-\epsilon_i^0 \\
&= \E[\ln(1-\delta + \delta \exp(-\sigma b_j +\mu_i -\mu_j+\sigma^2/2))]-\epsilon_i^0, \label{eq:decomp:contrib_of_var_C} 
\end{align}
where $b_j$ is standard normally distributed (see SI section \ref{sect:noise}). Continuing,
%last term of primary decomp, later splits into storage effects and effect of variation in E and C, per se  
\begin{align}
\olep_i^{EC} &= \E[\ln(1-\delta+\delta\exp(\sigma b_i +\mu_i)/\exp(\sigma b_j +\mu_j))]-\olep_i^E-\olep_i^C-\epsilon_i^0 \\
&= \E[\ln(1-\delta+\delta\exp(\sigma (b_i - b_j)+\mu_i-\mu_j))]-\olep_i^E-\olep_i^C-\epsilon_i^0, \label{eq:decomp:last_term_primary}
\end{align}
where $(b_i, b_j)$ is distributed as in SI section \ref{sect:noise}. Continuing,
%contrib of variation in E and C, per se  
\begin{align}
\olep_i^{(E\shp C)} &= \E[\ln(1-\delta+\delta\exp(\sigma b_i^\shp +\mu_i)/\exp(\sigma b_j^\shp + \mu_j))]-\olep_i^E-\olep_i^C-\epsilon_i^0 \\
&= \E[\ln(1-\delta+\delta\exp(\sigma(b_i^\shp - b_j^\shp)+\mu_i-\mu_j))]-\olep_i^E-\olep_i^C-\epsilon_i^0, \label{eq:decomp:contrib_of_EC_var_per_se}
\end{align}
where $b_i^\shp$ and $b_j^\shp$ are standard normally distributed and independent. Continuing,
%storage effects
\begin{equation}
\olep_i^{(EC)} = \E[\ln(1-\delta+\delta\exp(\sigma (b_i - b_j)+\mu_i-\mu_j))]-
\E[\ln(1-\delta+\delta\exp(\sigma (b_i^\shp - b_j^\shp)+\mu_i-\mu_j))],\label{eq:decomp:storage_effects}
\end{equation}
where $(b_i,b_j)$ is distributed as in SI section \ref{sect:noise}, and 
$b_i^\shp$ and $b_j^\shp$ are standard normal and independent. Continuing,
%contrib of ATA
\begin{equation}
\olep_i^{[EC]} = \E[\ln(1-\delta+\delta\exp(\sigma(b_i-b_j)+\mu_i-\mu_j))]-
\E[\ln(1-\delta+\delta\exp(\sigma(b_i^\nat-b_j^\nat)+\mu_i-\mu_j))],\label{eq:decomp:contrib_ATA_1}
\end{equation}
where $(b_i^\nat,b_j^\nat)$ have the same (standard normal) marginals and covariance as $(b_i,b_j)$ but are 
bivariate normal. Note, a choice has been made here: we could also have chosen $(b_i^\nat,b_j^\nat)$
to have the same standard normal marginals as $(b_i,b_j)$, but with covariance chosen such that
the Pearson, Spearman, or Kendall correlation of $E_i^\nat = \exp(\sigma b_i^\nat +\mu_i)$
and $C_{i \bs i}^\nat = \exp(\sigma b_j^\nat +\mu_j)/\delta$ matches that of $E_i = \exp(\sigma b_i +\mu_i)$
and $C_{i \bs i} = \exp(\sigma b_j +\mu_j)$. But the choice we made seems 
the most natural for the log-normal fecundities lottery models (and also for the 
beta fecundities lottery model - see below). 
Continuing, $\olep_i^{[E \nat C]}=\olep_i^{(EC)}-\olep_i^{[EC]}$ is available by subtracting expression (\ref{eq:decomp:contrib_ATA_1})
from expression (\ref{eq:decomp:storage_effects}), i.e., 
\begin{equation}
\olep_i^{[E \nat C]} = \E[\ln(1-\delta+\delta\exp(\sigma(b_i^\nat-b_j^\nat)+\mu_i-\mu_j))] - 
\E[\ln(1-\delta+\delta\exp(\sigma (b_i^\shp - b_j^\shp)+\mu_i-\mu_j))].\label{eq:decomp:contrib_EC}
\end{equation}
This completes the calculation of all the terms of the decomposition (\ref{eq:decomp_overall_IGR})  of $\olr_{i \bs i}$ 
for the log-normal fecundities lottery model.

%The second of the two growth rate decompositions
We next decompose $\olr_{j \bs i}$ for the log-normal fecundities lottery model [see (\ref{eq:decomp_overall_rjbsi})]. We have 
\begin{equation}
E_j = B_j = \exp(\sigma b_j + \mu_j)
\end{equation}
\begin{equation}
C_{j \bs i} = B_j/\delta = \exp(\sigma b_j + \mu_j)/\delta
\end{equation}
\begin{align}
\olr_{j \bs i} &= \E[\ln(1-\delta+E_j/C_{j \bs i})] \\
&= \E[\ln(1-\delta+\delta B_j/B_j)] \\
&= 0
\end{align}
\begin{equation}
\overline{E}_j = \exp(\mu_j+\sigma^2/2)
\end{equation}
\begin{equation}
\overline{C}_{j \bs i} = \exp(\mu_j + \sigma^2/2)/\delta
\end{equation}
%baseline
\begin{align}
\epsilon_j^0 &= r_j(\overline{E}_j,\overline{C}_{j \bs i}) \\
&= \ln \left( 1-\delta+\delta \frac{\exp(\mu_j + \sigma^2/2)}{\exp(\mu_j + \sigma^2/2)} \right) \\
&= 0 \label{eq:decomp:baseline_j}
\end{align}
and
%contrib of variation in E
\begin{align}
\olep_j^E &= \E[r_j(E_j,\overline{C}_{j \bs i})]-\epsilon_j^0 \\
&= \E[\ln(1-\delta+\delta B_j/\overline{B}_j)]-\epsilon_j^0 \\
&= \E \left[ \ln \left(1-\delta+\delta\frac{\exp(\sigma b_j + \mu_j)}{\exp(\mu_j+\sigma^2/2)} \right) \right]-\epsilon_j^0 \\
&= \E[\ln(1-\delta+\delta \exp(\sigma b_j - \sigma^2/2))]-\epsilon_j^0, \label{eq:decomp:contrib_of_var_E_j}
\end{align}
where $b_j$ is standard normally distributed (see SI section \ref{sect:noise}). Continuing,
%contrib of variation in C
\begin{align}
\olep_j^C &= \E[r_j(\overline{E}_j,C_{j \bs i})]-\epsilon_j^0 \\
&= \E \left[ \ln \left(1-\delta+\delta \frac{\overline{B}_j}{B_j} \right) \right]-\epsilon_j^0 \\
&= \E \left[ \ln \left(1-\delta+\delta \frac{\exp(\mu_j+\sigma^2/2)}{\exp(\sigma b_j +\mu_j)} \right) \right]-\epsilon_j^0 \\
&= \E[\ln(1-\delta+\delta \exp(-\sigma b_j+\sigma^2/2))]-\epsilon_j^0,\label{eq:decomp:contrib_of_var_C_j}
\end{align}
where again $b_j$ is standard normally distributed (see SI section \ref{sect:noise}). Continuing,
%last term of primary decomp, later splits into storage effects and effect of variation in E and C, per se  
\begin{align}
\olep_j^{EC} &= \E[r_j(E_j,C_{j \bs i})]-\olep_j^E-\olep_j^C-\epsilon_j^0 \\
&= \E[\ln(1-\delta+\delta B_j/B_j)]-\olep_j^E-\olep_j^C-\epsilon_j^0 \\
&= -\olep_j^E-\olep_j^C-\epsilon_j^0.\label{eq:decomp:j:EC}
\end{align}
Continuing,
%contrib of variation in E and C, per se  
\begin{align}
\olep_j^{(E\shp C)} &= \E[r_j(E_j^\shp , C_{j \bs i}^\shp )]-\olep_j^E-\olep_j^C-\epsilon_j^0 \\
&= \E \left[ \ln \left(1-\delta+\delta \frac{B_j^\shp}{B_j} \right) \right]-\olep_j^E-\olep_j^C-\epsilon_j^0 \\
&= \E \left[ \ln \left(1-\delta+\delta \frac{\exp(\sigma b_j^\shp + \mu_j)}{\exp(\sigma b_j + \mu_j)} \right) \right]-\olep_j^E-\olep_j^C-\epsilon_j^0 \\
&= \E[\ln(1-\delta+\delta \exp(\sigma(b_j^\shp - b_j)))]-\olep_j^E-\olep_j^C-\epsilon_j^0, \label{eq:decomp:j:EshpC}
\end{align}
where $(E_j^\shp , C_{j \bs i}^\shp)$ has the same marginals as $(E_j,C_{j \bs i})$ but has independent components;
$B_j^\shp$ is distributed in the same way as $B_j$ but is independent of it; and $b_j^\shp$ is distributed in the same
way as $b_j$ but is independent of it. Continuing,
%storage effects
\begin{align}
\olep_j^{(EC)} &= \E[r_j(E_j,C_{j \bs i})]-\E[r_j(E_j^\shp , C_{j \bs i}^\shp)] \\
&= -\E[r_j(E_j^\shp , C_{j \bs i}^\shp)] \\
&= -\E[\ln(1-\delta+\delta \exp(\sigma (b_j^\shp - b_j)))].\label{eq:decomp:j:pECp}
\end{align}
Continuing,
\begin{align}
\olep_j^{[EC]} &= \E[r_j(E_j,C_{j \bs i})] - \E[r_j(E_j^\nat , C_{j \bs i}^\nat)] \\
&= \olr_{j \bs i} - \olr_{j \bs i}^\nat \\
&= 0 \label{eq:decomp:j:EnatC}
\end{align}
because we showed in SI section \ref{SIsect:TheoryForLotteryBoth} that $\olr_{j \bs i}^\nat = \olr_{j \bs i}$, 
due to the fact that
$E_j$ and $C_{j \bs i}$ are perfectly linearly related to each other. Continuing,
\begin{align}
\olep_j^{[E \nat C]} &= \olep_j^{(EC)} - \olep_j^{[EC]} \\
&= - \E[\ln(1-\delta+\delta \exp(\sigma(b_j^\shp - b_j)))],\label{eq:decomp:j:EChard}
\end{align}
where again $b_j$ and $b_j^\shp$ are standard normally distributed and independent of each other.
This completes the calculation of all the terms of the decomposition of $\olr_{j \bs i}$ for the log-normal
fecundities lottery model.

Using the above formulas, we observe that all the terms of the decomposition of $\olr_{i \bs i}$ depend on 
$\delta$, $\sigma$, and $\mu_i - \mu_j$, but not separately on $\mu_i$ or $\mu_j$. The terms of the decomposition
of $\olr_{j \bs i}$ depend on $\delta$ and $\sigma$, but do not depend on $\mu_i$ or $\mu_j$ at all.
As discussed in the main text and SI section \ref{SIsect:scaling_factors}, we consider two alternative
values for the scaling factors, $q_{ij}$, namely $q_{ij}=1$ and a value which is shown in 
SI section \ref{SIsect:TheoryForLotteryBoth}
to equal, for the lottery model (both versions), the quantity
\begin{equation}
q_{ij} = \frac{\overline{B}_i}{\overline{B}_j (1-\delta) +\overline{B}_i \delta}.
\end{equation}
For the log-normal fecundities lottery model, this is
\begin{align}
q_{ij} &= \frac{\exp(\mu_i)}{(1-\delta) \exp(\mu_j)+\delta \exp(\mu_i)} \\
&= \frac{\exp(-\mu_i)\exp(\mu_i)}{\exp(-\mu_i)[(1-\delta) \exp(\mu_j)+\delta \exp(\mu_i)]} \\
&= \frac{1}{(1-\delta)\exp(-(\mu_i-\mu_j))+\delta}.\label{eq:decomp:qnot1}
\end{align}
Thus the $q_{ij}$ either do not depend on $\mu_i$ or $\mu_j$ at all or they depend on the difference 
$\mu_i-\mu_j$, rather than depending separately on $\mu_i$ or $\mu_j$. Thus each of the terms of the 
decomposition (\ref{MT-eq:full_decomp}) from the main text
depends only on $\mu_i-\mu_j$ and not separately on $\mu_i$ or $\mu_j$, as stated in the Methods section of the main text.

We now want to show that, for the log-normal fecundities lottery model, 
all elements of our decompositions (\ref{eq:decomp_overall_IGR}) and (\ref{eq:decomp_overall_rjbsi}), as well
as $q_{ij}$, and therefore all elements of our decomposition (\ref{eq:decomp_overall_delta}), are the same 
for our left- and right-tail associated cases, as was stated in Methods in the main text. Using the notation 
$(E_i^{(l)},C_{i \bs i}^{(l)})=(B_i^{(l)},B_j^{(l)}/\delta)=(\exp(\sigma b_i^{(l)} + \mu_i),
\exp(\sigma b_j^{(l)} + \mu_j)/\delta)$ and 
$(E_i^{(r)},C_{i \bs i}^{(r)})=(B_i^{(r)},B_j^{(r)}/\delta)=(\exp(\sigma b_i^{(r)}+\mu_i),\exp(\sigma b_j^{(r)}+\mu_j)/\delta)$
for the left- and right-tail associated cases, respectively, we note that the marginal distributions of
$(b_i^{(l)},b_j^{(l)})$ are the same as those of $(b_i^{(r)},b_j^{(r)})$, and so likewise the marginals of 
$(B_i^{(l)},B_j^{(l)}/\delta)$ are the same as those of $(B_i^{(r)},B_j^{(r)}/\delta)$.
So any component of (\ref{eq:decomp_overall_IGR}), or $q_{ij}$, will not depend on the choice
of our left- or right-tail associated noise cases as long as it depends only on marginal distributions.
But it is easy to see that $q_{ij}$ depends only on marginals, since $q_{ij}=\exp(\mu_i)/[(1-\delta)\exp(\mu_j)+\delta\exp(\mu_i)]$  
depends only on $\mu_i$, $\mu_j$ and $\delta$, and these are parameters of the marginal distributions of 
$(b_i,b_j)$. The alternative value $q_{ij}=1$ is constant, so also takes the same value for both our
left- and right-tail association noise cases. It is also easy to see from the definitions of $\epsilon_i^0$, 
$\olep_i^E$, $\olep_i^C$, and $\olep_i^{(E \shp C)}$ that these quantities only depend on marginals.

Whereas $\olep_i^{[E \nat C]} = \E[r_i(E_i^\nat , C_{i \bs i}^\nat )]-\E[r_i(E_i^\shp ,C_{i \bs i}^\shp)]$ depends on
more than just marginals, this quantity is still independent of the choice between our left- and right-tail-association 
cases because the bivariate random variables $(E_i^\nat , C_{i \bs i}^\nat )$ and 
$(E_i^\shp ,C_{i \bs i}^\shp)$ have had their tail association removed, and the only differences 
between $(E_i^{(l)},C_{i \bs i}^{(l)})$ and $(E_i^{(r)},C_{i \bs i}^{(r)})$ are in their tail association
properties (i.e., these two bivariate distributions have the same marginals and covariances).
In other words, $(E_i^\nat , C_{i \bs i}^\nat )$ is distributed in the same way for the left- and right-tail-association cases,
as is $(E_i^\shp ,C_{i \bs i}^\shp)$. 

We now examine $\olep_i^{[EC]}$, which, by (\ref{eq:decomp:contrib_ATA_1}), equals 
\begin{equation}
\olep_i^{[EC]} = \E[\ln(1-\delta+\delta\exp(\sigma(b_i-b_j)+\mu_i-\mu_j)]-
\E[\ln(1-\delta+\delta\exp(\sigma(b_i^\nat-b_j^\nat)+\mu_i-\mu_j)].\label{eq:rep1}
\end{equation}
But $(b_i^\nat,b_j^\nat)$ is a bivariate normal random variable constructed to have the same marginals and 
covariance as $(b_i,b_j)$, and the marginals and covariance of $(b_i^{(l)},b_j^{(l)})$ are the same as those of
$(b_i^{(r)},b_j^{(r)})$, so $(b_i^{\nat,(l)},b_j^{\nat,(l)})$ is distributed in the same way as 
$(b_i^{\nat,(r)},b_j^{\nat,(r)})$. So the second term on the right of (\ref{eq:rep1}) is independent
of the choice between our left- and right-tail-associated noise cases. Now examining 
$\E[\ln(1-\delta+\delta\exp(\sigma(b_i-b_j)+\mu_i-\mu_j))]$, 
we define $\beta_1=-b_2$ and $\beta_2=-b_1$,
and we note that $(\beta_1^{(l)},\beta_2^{(l)})$ is distributed in the same way as 
$(b_1^{(r)},b_2^{(r)})$; likewise, $(\beta_1^{(r)},\beta_2^{(r)})$ is distributed in the same way as 
$(b_1^{(l)},b_2^{(l)})$. So we then have 
\begin{align}
\E[\ln(1-\delta+\delta\exp(\sigma(b_i^{(l)}-b_j^{(l)})+\mu_i-\mu_j))] 
&= \E[\ln(1-\delta+\delta\exp(\sigma(\beta_i^{(r)}-\beta_j^{(r)})+\mu_i+\mu_j))] \\
&= \E[\ln(1-\delta+\delta\exp(\sigma(-b_j^{(r)}+b_i^{(r)})+\mu_i-\mu_j))] \\
&= \E[\ln(1-\delta+\delta\exp(\sigma(b_i^{(r)}-b_j^{(r)})+\mu_i-\mu_j))], 
\end{align}
which completes the proof that $\olep_i^{[EC]}$ is independent of left- versus right-tail associated noise.
For the terms of the decomposition (\ref{eq:decomp_overall_rjbsi}), it suffices to look at the equations for those terms, 
above, in this section, and note that all those terms depend only on marginals. 

\subsection{Theory and plotting simplifications for the beta fecundities lottery model}\label{SIsect:TheoryForLotteryBeta}

We first compute all terms of the decomposition (\ref{eq:decomp_overall_IGR}) of $\olr_{i \bs i}$ for the 
beta fecundities lottery model. Defining, for this section, $\beta_i=F_\beta^{-1} \circ \varphi(b_i)$ 
where $F_\beta$ is the CDF of a beta distribution with parameters $0.5,0.5$ and $\varphi$ is the CDF of 
a standard normal distribution, we have $B_i = \eta_i \beta_i$. Then, using the formulas of 
SI section \ref{SIsect:other_mechanisms}, we have
\begin{equation}
E_i = B_i = \eta_i \beta_i 
\end{equation}
\begin{equation}
B_j = \eta_j \beta_j 
\end{equation}
\begin{equation}
C_{i \bs i} = \frac{B_j}{\delta} = \frac{\eta_j}{\delta}\beta_j
\end{equation}
\begin{equation}
\overline{E}_i = \overline{B}_i = \frac{\eta_i}{2} 
\end{equation}
\begin{equation}
\overline{B}_j = \frac{\eta_j}{2} 
\end{equation}
\begin{equation}
\overline{C}_{i \bs i} = \frac{\eta_j}{2 \delta} 
\end{equation}
\begin{equation}
r_{i \bs i} = \ln\left(1-\delta+\delta \frac{B_i}{B_j} \right) = \ln\left(1-\delta+\delta\frac{\eta_i \beta_i}{\eta_j \beta_j}\right)\label{eq:103}
\end{equation}
\begin{equation}
\epsilon_i^0 = \ln\left( 1-\delta+\delta \frac{\eta_i}{\eta_j}  \right) \label{eq:104}
\end{equation}
\begin{equation}
\olep_i^E = \E\left[ \ln\left( 1-\delta+\delta \frac{2\eta_i \beta_i}{\eta_j}  \right)  \right]-\epsilon_i^0 \label{eq:105}
\end{equation}
\begin{equation}
\olep_i^C = \E\left[ \ln\left(1-\delta+\delta\frac{\eta_i}{2\eta_j \beta_j}\right)  \right]-\epsilon_i^0 \label{eq:106}
\end{equation}
\begin{equation}
\olep_i^{EC} = \E\left[ \ln\left( 1-\delta+\delta\frac{\eta_i \beta_i}{\eta_j \beta_j}  \right) \right]-\olep_i^E-\olep_i^C-\epsilon_i^0
\end{equation}
and
\begin{equation}
\olep_i^{(E\shp C)} = \E\left[ \ln\left( 1-\delta+\delta\frac{\eta_i \beta_i^\shp}{\eta_j \beta_j^\shp}  \right)  \right]-\olep_i^E-\olep_i^C-\epsilon_i^0,\label{eq:108}
\end{equation}
where $(\beta_i^\shp,\beta_j^\shp)=(F_\beta^{-1} \circ \varphi (b_i^\shp),F_\beta^{-1} \circ \varphi(b_j^\shp))$.
Here, $b_i^\shp$ and $b_j^\shp$ are standard normal and independent. Continuing,
\begin{equation}
\olep_i^{(EC)} = \E\left[ \ln\left( 1-\delta+\delta\frac{\eta_i \beta_i}{\eta_j \beta_j}  \right) \right]
-\E\left[ \ln\left( 1-\delta+\delta\frac{\eta_i\beta_i^\shp}{\eta_j \beta_j^\shp} \right) \right].
\end{equation}
Continuing,
\begin{equation}
\olep_i^{[EC]}=\E\left[ \ln\left( 1-\delta+\delta\frac{\eta_i \beta_i}{\eta_j \beta_j} \right) \right]-
\E\left[ \ln\left( 1-\delta+\delta\frac{\eta_i \beta_i^\nat}{\eta_j \beta_j^\nat}  \right)  \right],\label{eq:110}
\end{equation}
where $(\beta_i^\nat,\beta_j^\nat)=(F_\beta^{-1} \circ \varphi (b_i^\nat),F_\beta^{-1} \circ \varphi(b_j^\nat))$,
and $(b_i^\nat,b_j^\nat)$ has the same (standard normal) marginals and covariance as $(b_i,b_j)$ but is
bivariate normal. Note that a choice has been made here: we could have chosen $(b_i^\nat,b_j^\nat)$
to have the same (standard normal) marginals as $(b_i,b_j)$, but with covariance chosen so that
the Pearson, Spearman, or Kendall correlation of $E_i^\nat = \eta_i F_\beta^{-1} \circ \varphi (b_i^\nat)$
and $C_{i \bs i}^\nat = \eta_j F_\beta^{-1} \circ \varphi (b_j^\nat)/\delta$ is the same as that of 
$E_i = \eta_i F_\beta^{-1} \circ \varphi (b_i)$ and $C_{i \bs i} = \eta_j F_\beta^{-1} \circ \varphi (b_j)/\delta$.
But the choice we made seems the most natural under the circumstances.
Continuing, $\olep_i^{[E\nat C]}=\olep_i^{(E C)}-\olep_i^{[E C]}$ is available by subtraction, i.e.,
\begin{equation}
\olep_i^{[E\nat C]} = \E\left[ \ln\left(1-\delta+\delta\frac{\eta_i \beta_i^\nat}{\eta_j \beta_j^\nat}  \right)  \right] - 
\E\left[ \ln\left(1-\delta+\delta\frac{\eta_i \beta_i^\shp}{\eta_j \beta_j^\shp}  \right)  \right].\label{eq:111}
\end{equation}
This completes the calculation of all the terms of the decomposition 
(\ref{eq:decomp_overall_IGR}) of $\olr_{i \bs i}$ for the beta fecundities lottery model.

We next decompose $\olr_{j \bs i}$ for the beta fecundities lottery model [see (\ref{eq:decomp_overall_rjbsi})]. We have 
\begin{equation}
E_j = B_j = \eta_j \beta_j
\end{equation}
\begin{equation}
C_{j \bs i} = \frac{B_j}{\delta} = \frac{\eta_j \beta_j}{\delta}
\end{equation}
\begin{equation}
\overline{E}_j = \frac{\eta_j}{2}
\end{equation}
\begin{equation}
\overline{C}_{j \bs i} = \frac{\eta_j}{2\delta}
\end{equation}
\begin{equation}
\overline{B}_j = \frac{\eta_j}{2}
\end{equation}
\begin{align}
\olr_{j \bs i} &= \E\left[ \ln\left( 1-\delta+\frac{E_j}{C_{j \bs i}} \right) \right] \\
&= \E\left[ \ln\left( 1-\delta+\delta\frac{B_j}{B_j} \right) \right] \\
&= 0 \label{eq:119}
\end{align}
\begin{equation}
\epsilon_j^0 = \ln \left( 1-\delta+\delta\frac{\eta_j /2}{\eta_j /2} \right) = 0 \label{eq:120}
\end{equation}
\begin{align}
\olep_j^E &= \E\left[ \ln\left( 1-\delta+\delta\frac{2\eta_j \beta_j}{\eta_j} \right) \right] - \epsilon_j^0 \\
&= \E\left[ \ln\left( 1-\delta+2 \delta \beta_j \right) \right] \label{eq:122}
\end{align}
\begin{align}
\olep_j^C &= \E\left[ \ln\left( 1-\delta+\delta\frac{\eta_j}{2\eta_j\beta_j} \right) \right]-\epsilon_j^0 \\
&= \E\left[ \ln\left( 1-\delta+\frac{\delta}{2\beta_j} \right) \right] \label{eq:124}
\end{align}
\begin{align}
\olep_j^{EC} &= \E\left[  \ln\left( 1-\delta+\delta\frac{B_j}{B_j} \right)\right]-\olep_j^E-\olep_j^C-\epsilon_j^0 \\
&= -\olep_j^E - \olep_j^C
\end{align}
\begin{align}
\olep_j^{(E\shp C)} &= \E\left[ \ln\left( 1-\delta+\delta\frac{B_j}{B_j^\shp} \right) \right]-\olep_j^E-\olep_j^C-\epsilon_j^0 \\
&= \E\left[ \ln\left( 1-\delta+\delta\frac{\beta_j}{\beta_j^\shp} \right) \right]-\olep_j^E-\olep_j^C, \label{eq:128}
\end{align}
where $(\beta_j,\beta_j^\shp)=(F_\beta^{-1} \circ \varphi (b_j),F_\beta^{-1} \circ \varphi (b_j^\shp))$ and
$b_j^\shp$ is distributed in the same way as $b_j$ but is independent of it. Continuing,
\begin{align}
\olep_j^{(EC)} &= \E\left[ \ln\left(1-\delta+\delta \frac{B_j}{B_j} \right)  \right]-
\E\left[ \ln\left(1-\delta+\delta\frac{B_j}{B_j^\shp}  \right)  \right] \\
&= -\E\left[\ln\left( 1-\delta+\delta\frac{\beta_j}{\beta_j^\shp} \right)  \right].
\end{align}
Continuing,
\begin{align}
\olep_j^{[EC]} &= \E\left[ \ln\left(1-\delta+\delta \frac{B_j}{B_j} \right)  \right]-
\E\left[ \ln\left(1-\delta+\delta\frac{B_j^\nat}{B_j^\nat}  \right)  \right] \\
&= 0.\label{eq:132}
\end{align}
We showed already (SI section \ref{SIsect:TheoryForLotteryBoth} and 
\ref{SIsect:TheoryForLotteryLogNorm}) that this is $0$ because $E_j$ and $C_{j \bs i}$
are linearly related to each other. Continuing,
\begin{align}
\olep_j^{[E \nat C]} &= \olep_j^{(EC)}-\olep_j^{[EC]} \\
&= -\E\left[ \ln\left( 1-\delta+\delta\frac{\beta_j}{\beta_j^\shp}  \right)  \right].\label{eq:134}
\end{align}
This completes the calculation of all the terms of the decomposition of $\olr_{j \bs i}$
for the beta fecundities lottery model.

Using the above formulas, we observe that all the terms of the decomposition of $\olr_{i \bs i}$ depend on 
$\delta$, $\sigma$, and $\eta_i/\eta_j$, but not separately on $\eta_i$ or $\eta_j$. The terms of the decomposition
of $\olr_{j \bs i}$ depend on $\delta$ and $\sigma$, but do not depend on $\eta_i$ or $\eta_j$ at all.
As discussed in the main text and SI section \ref{SIsect:scaling_factors}, we consider two alternative
values for the scaling factors, $q_{ij}$, namely $q_{ij}=1$ and 
\begin{equation}
q_{ij} = \frac{\overline{B}_i}{\overline{B}_j (1-\delta) +\overline{B}_i \delta}.
\end{equation}
For the beta fecundities lottery model, this is
\begin{align}
q_{ij} &= \frac{\eta_i}{\eta_j(1-\delta)+\eta_i \delta} \\
&= \frac{\eta_i/\eta_j}{(1-\delta)+\frac{\eta_i}{\eta_j}\delta}.\label{eq:137}
\end{align}
Thus the $q_{ij}$ either do not depend on $\eta_i$ or $\eta_j$ at all or they depend on the quotient 
$\eta_i/\eta_j$, rather than depending separately on $\eta_i$ or $\eta_j$. Thus each of the terms of the 
decomposition (\ref{MT-eq:full_decomp}) from the main text
depends only on $\eta_i/\eta_j$ and not separately on $\eta_i$ or $\eta_j$, as stated in the Methods 
section of the main text.

\section{Efficient computation}\label{sect:efficient_computation}

\subsection{Efficient computation for the log-normal fecundities lottery model}\label{sect:efficient_computation_lognormal}

We here elaborate how the terms in the decompositions (\ref{eq:decomp_overall_IGR}), (\ref{eq:decomp_overall_rjbsi})
and (\ref{eq:decomp_overall_delta}) are computed rapidly, for the log-normal fecundities lottery model.

First, for a large integer $M$ (we used $M=\Sexpr{M}$),
carry out the following steps once.
\begin{enumerate}
\item Generate $M$ independent points $u^{(k)}$, $k=1,\ldots,M$, from a standard normal distribution.
\item Generate $M$ independent points $(b_i^{(k)},b_j^{(k)})$, $k=1,\ldots,M$, as in SI section \ref{sect:noise}, 
which are left-tail associated and which have standard-normal marginals. 
\item Again as in SI section \ref{sect:noise}, generate $M$ independent points $(b_i^{\nat,(k)},b_j^{\nat,(k)})$, 
$k=1,\ldots,M$, from a bivariate normal distribution with component variances $1$ and Pearson correlation the same as 
$(b_i^{(k)},b_j^{(k)})$.
\end{enumerate}
These data are stored and used repeatedly below. This provides computational efficiency because 
random number generation is computationally expensive.

Next, given values of the parameters $\delta$, $\mu_i - \mu_j$, and $\sigma$, proceed as follows to get estimates of the 
terms of the decomposition (\ref{eq:decomp_overall_IGR}).
\begin{enumerate}
\item Compute $\epsilon_i^0$ following (\ref{eq:decomp:baseline}), which is a simple formula of $\delta$ and 
$\mu_i - \mu_j$, not requiring use of the random samples described above. This gives an exact value of
$\epsilon_i^0$, not an estimate.
\item Estimate $\olep_i^E$, following (\ref{eq:decomp:contrib_of_var_E}), as 
$\widehat{\olep_i^E}=\mean_k [\ln(1-\delta+\delta \exp(\sigma u^{(k)}+\mu_i-\mu_j-\sigma^2/2))]-\epsilon_i^0$, an estimate with 
standard error $\se \left( \widehat{\olep_i^E} \right) = \sd_k [\ln(1-\delta+\delta \exp(\sigma u^{(k)}+\mu_i-\mu_j-\sigma^2/2))]/\sqrt{M}$,
where $\sd(\cdot)$ denotes sample standard deviation.
\item Estimate $\olep_i^C$, following (\ref{eq:decomp:contrib_of_var_C}), as 
$\widehat{\olep_i^C}=\mean_k [\ln(1-\delta+\delta \exp(-\sigma u^{(k)}+\mu_i-\mu_j+\sigma^2/2))]-\epsilon_i^0$, which has 
standard error $\se \left( \widehat{\olep_i^C} \right) = \sd_k[\ln(1-\delta+\delta \exp(-\sigma u^{(k)}+\mu_i-\mu_j+\sigma^2/2))]/\sqrt{M}$.
\item Note that $\tilde{b}_i^\shp-\tilde{b}_j^\shp$ in (\ref{eq:decomp:contrib_of_EC_var_per_se}) is normally distributed
with mean $0$ and variance $2$, so we can estimate $\olep_i^{(E \shp C)}$, following (\ref{eq:decomp:contrib_of_EC_var_per_se}),
as $\widehat{\olep_i^{(E \shp C)}}=\mean_k[\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}+\mu_i-\mu_j))]-\widehat{\olep_i^E}-\widehat{\olep_i^C}-\epsilon_i^0.$ The standard error of this expression is 
$\se \left( \widehat{\olep_i^{(E \shp C)}} \right) = \sd_k [\ln(1-\delta+\delta\exp(\sigma \sqrt{2} u^{(k)}+\mu_i-\mu_j))-
\ln(1-\delta+\delta\exp(\sigma u^{(k)}+\mu_i-\mu_j-\sigma^2/2))-
\ln(1-\delta+\delta\exp(-\sigma u^{(k)}+\mu_i-\mu_j+\sigma^2/2))]/\sqrt{M}$. 
\item Estimate $\olep_i^{[E \nat C]}$, following (\ref{eq:decomp:contrib_EC}), as
$\widehat{\olep_i^{[E \nat C]}}=\mean_k[\ln(1-\delta+\delta\exp(\sigma(b_i^{\nat,(k)}-b_j^{\nat,(k)})+\mu_i-\mu_j))]-\mean_k[\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}+\mu_i-\mu_j))]$. The standard error of this expression is 
$\se \left( \widehat{\olep_i^{[E \nat C]}} \right) = \sqrt{s_1^2+s_2^2}$, where $s_1=\sd_k [\ln(1-\delta+\delta\exp(\sigma(b_i^{\nat,(k)}-b_j^{\nat,(k)})+\mu_i-\mu_j))]/\sqrt{M}$
and $s_2=\sd_k [\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}+\mu_i-\mu_j))]/\sqrt{M}$.
\item Estimate $\olep_i^{[EC]}$, following (\ref{eq:decomp:contrib_ATA_1}), as 
$\widehat{\olep_i^{[EC]}} = \mean_k[\ln(1-\delta+\delta\exp(\sigma(b_i^{(k)}-b_j^{(k)})+\mu_i-\mu_j))]-
\mean_k[\ln(1-\delta+\delta\exp(\sigma(b_i^{\nat,(k)}-b_j^{\nat,(k)})+\mu_i-\mu_j))].$ The standard
error of this expression is $\se \left( \widehat{\olep_i^{[EC]}} \right)=\sqrt{s_3^2+s_1^2}$, where
$s_1$ is as above, and $s_3=\sd_k[\ln(1-\delta+\delta\exp(\sigma(b_i^{(k)}-b_j^{(k)})+\mu_i-\mu_j))]/\sqrt{M}.$
\item Finally, estimate $\olr_{i \bs i}$, following (\ref{eq:base_IGR}), as 
$\widehat{\olr_{i \bs i}}=\mean_k[\ln(1-\delta+\delta\exp(\sigma(b_i^{(k)}-b_j^{(k)})+\mu_i-\mu_j))],$
which has standard error $s_3$ from above.
\end{enumerate}
It is easy to see that $\widehat{\olr_{i \bs i}}=\epsilon_i^0+\widehat{\olep_i^E}+\widehat{\olep_i^C}+\widehat{\olep_i^{(E \shp C)}}+
\widehat{\olep_i^{[E \nat C]}}+\widehat{\olep_i^{[EC]}},$ i.e., the decomposition (\ref{eq:decomp_overall_IGR}) applies 
at the level of the estimators, as well as at the level of the quantities being estimated.

Next, proceed as follows to get estimates of the terms in the decomposition (\ref{eq:decomp_overall_rjbsi}). 
\begin{enumerate}
\item Use $\epsilon_j^0=0$, as in (\ref{eq:decomp:baseline_j}), and this is the exact value.
\item Estimate $\olep_j^E$, following (\ref{eq:decomp:contrib_of_var_E_j}), as
$\widehat{\olep_j^E}=\mean_k[\ln(1-\delta+\delta\exp(\sigma u^{(k)}-\sigma^2/2))]-\epsilon_j^0$, an estimate
with standard error $\se \left( \widehat{\olep_j^E} \right) = \sd_k [\ln(1-\delta+\delta\exp(\sigma u^{(k)}-\sigma^2/2))]/\sqrt{M}$.
\item Estimate $\olep_j^C$, following (\ref{eq:decomp:contrib_of_var_C_j}), as
$\widehat{\olep_j^C}=\mean_k[\ln(1-\delta+\delta\exp(-\sigma u^{(k)}+\sigma^2/2))]-\epsilon_j^0$, which has 
standard error $\se \left( \widehat{\olep_j^C} \right) = \sd_k [\ln(1-\delta+\delta\exp(-\sigma u^{(k)}+\sigma^2/2))]/\sqrt{M}$.
\item Note that $b_j$ and $b_j^\shp$ in (\ref{eq:decomp:j:EshpC}) are standard normally distributed and
independent, so $b_j^\shp - b_j$ is normally distributed with mean $0$ and variance $2$. So we can 
estimate $\olep_j^{(E \shp C)}$, following (\ref{eq:decomp:j:EshpC}), as 
$\widehat{\olep_j^{(E \shp C)}} = \mean_k [\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}))]-\widehat{\olep_j^E}-\widehat{\olep_j^C}-\epsilon_j^0$.
The standard error of this expression is $\se \left(  \widehat{\olep_j^{(E \shp C)}} \right) = 
\sd_k[\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}))-\ln(1-\delta+\delta\exp(\sigma u^{(k)}-\sigma^2/2))-
\ln(1-\delta+\delta\exp(-\sigma u^{(k)}+\sigma^2/2))]/\sqrt{M}$.
\item Estimate $\olep_j^{[E \nat C]}$, following (\ref{eq:decomp:j:EChard}), as $\widehat{\olep_j^{[E \nat C]}}=\mean_k [-\ln(1-\delta+\delta \exp(\sigma \sqrt{2} u^{(k)}))],$ which has $\se \left( \widehat{\olep_j^{[E \nat C]}} \right) = \sd_k[-\ln(1-\delta+\delta \exp(\sigma \sqrt{2} u^{(k)}))]/\sqrt{M}$.
\item Use $\olep_j^{[EC]}=0$, following (\ref{eq:decomp:j:EnatC}). This is exact.
\item Finally, use $\olr_{j \bs i} = 0$, again exact. 
\end{enumerate}
As for (\ref{eq:decomp_overall_IGR}), it is again easy to see that (\ref{eq:decomp_overall_rjbsi}) applies for the 
estimates as well as for the quantities being estimated. 

Next, $q_{ij}$ can be taken (see SI section \ref{SIsect:scaling_factors}) to be, alternatively, $1$ or 
the quantity displayed in (\ref{eq:decomp:qnot1}). Hence the terms of the decomposition 
(\ref{eq:decomp_overall_delta}) can straightforwardly be etimated using our estimates elaborated 
above, as follows. There are two alternative versions of the estimators for this decomposition, corresponding 
to the alternative values for $q_{ij}$.
\begin{enumerate}
\item Compute $\Delta_i^0 = \epsilon_i^0 - q_{ij} \epsilon_j^0$, which is computed exactly, since 
the quantities described above for the components $\epsilon_i^0$, $\epsilon_j^0$ and $q_{ij}$ are exact, as opposed to being
estimates. Simplifying, since $\epsilon_j^0=0$, we have $\Delta_i^0 = \epsilon_i^0$.
\item Estimate $\Delta_i^E$ as $\widehat{\Delta_i^E}=\widehat{\olep_i^E}-q_{ij}\widehat{\olep_j^E}=
\mean_k[\ln(1-\delta+\delta\exp(\sigma u^{(k)}+\mu_i-\mu_j-\sigma^2/2))]-\epsilon_i^0-
q_{ij} \mean_k[\ln(1-\delta+\delta\exp(\sigma u^{(k)}-\sigma^2/2))],$ which has standard error 
$\se\left( \widehat{\Delta_i^E} \right)=\sd_k[\ln(1-\delta+\delta\exp(\sigma u^{(k)}+\mu_i-\mu_j-\sigma^2/2))-
q_{ij} \ln(1-\delta+\delta\exp(\sigma u^{(k)}-\sigma^2/2))]/\sqrt{M}.$
\item Estimate $\Delta_i^C$ as $\widehat{\Delta_i^C}=\widehat{\olep_i^C}-q_{ij}\widehat{\olep_j^C}=
\mean_k[\ln(1-\delta+\delta\exp(-\sigma u^{(k)}+\mu_i-\mu_j+\sigma^2/2))]-
\epsilon_i^0-q_{ij}\mean_k[\ln(1-\delta+\delta\exp(-\sigma u^{(k)}+\sigma^2/2))],$ which has standard error
$\se \left( \widehat{\Delta_i^C} \right)=\sd_k[\ln(1-\delta+\delta\exp(-\sigma u^{(k)}+\mu_i-\mu_j+\sigma^2/2))-
q_{ij}\ln(1-\delta+\delta\exp(-\sigma u^{(k)}+\sigma^2/2))]/\sqrt{M}$.
\item Estimate $\Delta_i^{(E \shp C)}$ as $\widehat{\Delta_i^{(E \shp C)}} = \widehat{\olep_i^{(E \shp C)}}-q_{ij} \widehat{\olep_j^{(E \shp C)}}=
\mean_k[\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}+\mu_i-\mu_j))]-\widehat{\olep_i^E}-\widehat{\olep_i^C}-\epsilon_i^0-
q_{ij}[\mean_k [\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}))]-\widehat{\olep_j^E}-\widehat{\olep_j^C}-\epsilon_j^0].$
This simplifies to $\mean_k[\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}+\mu_i-\mu_j))]-
q_{ij}\mean_k[\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}))]-\widehat{\Delta_i^E}-\widehat{\Delta_i^C}-\Delta_i^0$, 
which can be straightforwardly shown has standard error
$\se \left( \widehat{\Delta_i^{(E \shp C)}} \right) = 
\sd_k[\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}+\mu_i-\mu_j))-
\ln(1-\delta+\delta\exp(\sigma u^{(k)}+\mu_i-\mu_j-\sigma^2/2))-
\ln(1-\delta+\delta\exp(-\sigma u^{(k)}+\mu_i-\mu_j+\sigma^2/2))-
q_{ij}\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}))+
q_{ij}\ln(1-\delta+\delta\exp(\sigma u^{(k)}-\sigma^2/2))+
q_{ij}\ln(1-\delta+\delta\exp(-\sigma u^{(k)}+\sigma^2/2))]/\sqrt{M}$.
\item Estimate $\Delta_i^{[E \nat C]}$ as $\widehat{\Delta_i^{[E \nat C]}}=\widehat{\olep_i^{[E \nat C]}}-q_{ij}\widehat{\olep_j^{[E \nat C]}}=
\mean_k[\ln(1-\delta+\delta\exp(\sigma(b_i^{\nat,(k)}-b_j^{\nat,(k)})+\mu_i-\mu_j))]-
\mean_k[\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}+\mu_i-\mu_j))]+
q_{ij}\mean_k[\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}))],$ which one can straightforwardly show has standard error
$\sqrt{s_1^2+s_2^2}$, where $s_1=\sd_k[\ln(1-\delta+\delta\exp(\sigma(b_i^{\nat,(k)}-b_j^{\nat,(k)})+\mu_i-\mu_j))]/\sqrt{M}$ 
and $s_2=\sd_k[\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}+\mu_i-\mu_j))-q_{ij}\ln(1-\delta+\delta\exp(\sigma\sqrt{2}u^{(k)}))]/\sqrt{M}$.
\item For $\Delta_i^{[EC]}$, we recall that $\olep_j^{[EC]}=0$, so $\Delta_i^{[EC]}=\olep_i^{[EC]}$. So we use
$\widehat{\olep_i^{[EC]}}$ for $\widehat{\Delta_i^{[EC]}}$.
\item Finally, we can also estimate $\olr_{i \bs i}-q_{ij}\olr_{j \bs i}$ simply as $\widehat{\olr_{i \bs i}}$
since $\olr_{j \bs i}=0$.
\end{enumerate}
As for (\ref{eq:decomp_overall_IGR}) and (\ref{eq:decomp_overall_rjbsi}), it is again the case that (\ref{eq:decomp_overall_delta})
applies for the estimators as well as for the quantities being estimated.

\subsection{Efficient computation for the beta fecundities lottery model}\label{sect:efficient_computation_beta}

We here elaborate how the terms in the decompositions (\ref{eq:decomp_overall_IGR}), (\ref{eq:decomp_overall_rjbsi})
and (\ref{eq:decomp_overall_delta}) are computed rapidly, for the beta fecundities lottery model.

First, for a large integer $M$ (we used $M=\Sexpr{M}$),
carry out the following steps once:
\begin{enumerate}
\item Generate $M$ independent points $(\beta_i^{(k)},\beta_j^{(k)})=(F_\beta^{-1} \circ \varphi (b_i^{(k)}),F_\beta^{-1} \circ \varphi (b_j^{(k)}))$,
$k=1,\ldots,M$, where $(b_i^{(k)},b_j^{(k)})$ are left- or right-tail associated points generated as in SI section \ref{sect:noise},
depending on whether one is currently considering the left- or right-tail associated case.
\item Generate $M$ independent points $(\beta_i^{\shp,(k)},\beta_j^{\shp,(k)})=(F_\beta^{-1} \circ \varphi (b_i^{\shp,(k)}),
F_\beta^{-1} \circ \varphi (b_j^{\shp,(k)}))$, $k=1,\ldots,M$, where $b_i^{\shp,(k)}$ and $b_j^{\shp,(k)}$ are standard normal and 
independent. Make these points also independent of the points $(\beta_i^{(k)},\beta_j^{(k)})$ generated above.
\item Generate $M$ independent points 
$(\beta_i^{\nat,(k)},\beta_j^{\nat,(k)})=(F_\beta^{-1} \circ \varphi (b_i^{\nat,(k)}),
F_\beta^{-1} \circ \varphi (b_j^{\nat,(k)}))$, $k=1,\ldots,M$, where the points $(b_i^{\nat,(k)},b_j^{\nat,(k)})$
come from a bivariate normal distribution with standard normal marginals and Pearson correlation the same
as $(b_i^{(k)},b_j^{(k)})$ (see SI section \ref{sect:noise}). Make these points also independent of both sets of 
points generated above.
\end{enumerate}
These data are stored and used repeatedly below.

Next, given values of the parameters $\delta$ and $\eta_i/\eta_j$, proceed as follows to get estimates of the terms of the 
decomposition (\ref{eq:decomp_overall_IGR}).
\begin{enumerate}
%baseline
\item Compute $\epsilon_i^0$, following (\ref{eq:104}), which is a simple formula of $\delta$ and $\eta_i/\eta_j$, not 
requiring use of the random samples described above. This gives an exact values of $\epsilon_i^0$, not an estimate.
%E
\item Estimate $\olep_i^E$, following (\ref{eq:105}), as $\widehat{\olep_i^E}=
\mean_k[ \ln( 1-\delta+2\delta \frac{\eta_i}{\eta_j}\beta_i^{\shp,(k)}) ]-\epsilon_i^0$. This 
estimate has standard error $\se( \widehat{\olep_i^E})=
\sd_k[  \ln( 1-\delta+2\delta \frac{\eta_i}{\eta_j}\beta_i^{\shp,(k)}) ]/\sqrt{M}$, where 
$\sd (\cdot)$ denotes sample standard deviation.
%C
\item Estimate $\olep_i^C$, following (\ref{eq:106}), as $\widehat{\olep_i^C}=
\mean_k[ \ln( 1-\delta+\frac{\delta}{2} \frac{\eta_i}{\eta_j}\frac{1}{\beta_j^{\shp,(k)}}) ]-\epsilon_i^0$. 
This estimate has standard error $\se( \widehat{\olep_i^C})=
\sd_k[  \ln( 1-\delta+\frac{\delta}{2} \frac{\eta_i}{\eta_j}\frac{1}{\beta_j^{\shp,(k)}}) ]/\sqrt{M}$.
%E#C
\item Estimate $\olep_i^{(E \shp C)}$, following (\ref{eq:108}), as $\widehat{\olep_i^{(E \shp C)}}=
\mean_k[ \ln( 1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{\shp,(k)}}{\beta_j^{\shp,(k)}}) ]-
\widehat{\olep_i^E}-\widehat{\olep_i^C}-\epsilon_i^0$. The standard error of this estimate is 
$\se( \widehat{\olep_i^{(E \shp C)}}  )=
\sd_k [ \ln( 1-\delta+\delta \frac{\eta_i}{\eta_j}\frac{\beta_i^{\shp,(k)}}{\beta_j^{\shp,(k)}})-
\ln( 1-\delta+\frac{\delta}{2}\frac{\eta_i}{\eta_j}\frac{1}{\beta_j^{\shp,(k)}} )-
\ln( 1-\delta+2\delta\frac{\eta_i}{\eta_j}\beta_i^{\shp,(k)} )]/\sqrt{M}$.
%E||C
\item Estimate $\olep_i^{[E \nat C]}$, following (\ref{eq:111}), as $\widehat{\olep_i^{[E\nat C]}}=
\mean_k[\ln( 1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{\nat,(k)}}{\beta_j^{\nat,(k)}} )]-
\mean_k[\ln( 1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{\shp,(k)}}{\beta_j^{\shp,(k)}} )]$.
The standard error of this expression is $\sqrt{s_1^2+s_2^2}$, where 
$s_1=\sd_k[ \ln(1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{\nat,(k)}}{\beta_j^{\nat,(k)}}  )  ]/\sqrt{M}$
and $s_2=\sd_k[ \ln(  1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{\shp,(k)}}{\beta_j^{\shp,(k)}}) ]/\sqrt{M}$.
%[EC]
\item Esimate $\olep_i^{[EC]}$, following (\ref{eq:110}), as $\widehat{\olep_i^{[EC]}}=
\mean_k[\ln( 1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{(k)}}{\beta_j^{(k)}} )]-
\mean_k[\ln( 1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{\nat,(k)}}{\beta_j^{\nat,(k)}} )]$.
The standard error of this expression is $\sqrt{s_1^2+s_3^2}$, where $s_1$ is defined above, and 
$s_3=\sd_k[ \ln(1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{(k)}}{\beta_j^{(k)}}  )  ]/\sqrt{M}$.
%r
\item Finally, estimate $\olr_{i \bs i}$, following (\ref{eq:103}), as
$\widehat{\olr_{i \bs i}}=\mean_k[\ln(1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{(k)}}{\beta_j^{(k)}})]$,
which has standard error $s_3$ from above.
\end{enumerate}
It is easy to see that $\widehat{\olr_{i \bs i}}=\epsilon_i^0+\widehat{\olep_i^E}+\widehat{\olep_i^C}+\widehat{\olep_i^{(E \shp C)}}+
\widehat{\olep_i^{[E \nat C]}}+\widehat{\olep_i^{[EC]}},$ i.e., the decomposition (\ref{eq:decomp_overall_IGR}) applies 
at the level of the estimators, as well as at the level of the quantities being estimated.

Next, proceed as follows to get estimates of the terms in the decomposition (\ref{eq:decomp_overall_rjbsi}). 
\begin{enumerate}
%baseline
\item Use $\epsilon_j^0 = 0$, as in (\ref{eq:120}), and this is an exact value.
%E
\item Estimate $\olep_j^E$, following (\ref{eq:122}), as $\widehat{\olep_j^E}=\mean_k[\ln(1-\delta+2\delta\beta_j^{(k)})]$. This has
standard error $\se(\widehat{\olep_j^E})=\sd_k[\ln(1-\delta+2\delta\beta_j^{(k)})]/\sqrt{M}$.
%C
\item Estimate $\olep_j^C$, following (\ref{eq:124}), as $\widehat{\olep_j^C}=
\mean_k[\ln(1-\delta+\frac{\delta}{2}\frac{1}{\beta_j^{\shp,(k)}})]$, which has standard error $\se(\widehat{\olep_j^C})=
\sd_k[\ln(1-\delta+\frac{\delta}{2}\frac{1}{\beta_j^{\shp,(k)}})]/\sqrt{M}$.
%E#C
\item Estimate $\olep_j^{(E \shp C)}$, following (\ref{eq:128}), as $\widehat{\olep_j^{(E \shp C)}}=
\mean_k[\ln(1-\delta+\delta\frac{\beta_j^{(k)}}{\beta_j^{\shp,(k)}})]-\widehat{\olep_j^E}-\widehat{\olep_j^C}$. This has
standard error $\se(\widehat{\olep_j^{(E \shp C)}})=\sd_k[\ln(1-\delta+\delta\frac{\beta_j^{(k)}}{\beta_j^{\shp,(k)}})-
\ln(1-\delta+2\delta \beta_j^{(k)})-\ln(1-\delta+\frac{\delta}{2}\frac{1}{\beta_j^{\shp,(k)}})]/\sqrt{M}$.
%E||C
\item Estimate $\olep_j^{[E \nat C]}$, following (\ref{eq:134}), as $\widehat{\olep_j^{[E \nat C]}}=
-\mean_k[\ln(1-\delta+\delta\frac{\beta_j^{(k)}}{\beta_j^{\shp,(k)}})]$, which has standard error 
$\se(\widehat{\olep_j^{[E \nat C]}})=\sd_k[\ln(1-\delta+\delta\frac{\beta_j^{(k)}}{\beta_j^{\shp,(k)}})]/\sqrt{M}$.
%[EC]
\item Use $\olep_j^{[EC]}=0$, following (\ref{eq:132}). This is exact.
%r
\item Finally, use $\olr_{j \bs i} = 0$, following (\ref{eq:119}), again exact.
\end{enumerate}
As for (\ref{eq:decomp_overall_IGR}), it is again easy to see that (\ref{eq:decomp_overall_rjbsi})
applies for the estimates, as well as for the quantities being estimated.

Next, $q_{ij}$ can be taken (SI section \ref{sect:noise}) to be, alternatively, either $1$ or the quantity displayed in 
(\ref{eq:137}). Hence the terms of the decomposition (\ref{eq:decomp_overall_delta}) can straightforwardly be
estimated using our estimates elaborated above, as follows. There are two versions of each estimator, corresponding
to the alternative values of $q_{ij}$. 
\begin{enumerate}
%baseline
\item Compute $\Delta_i^0 = \epsilon_i^0 - q_{ij} \epsilon_j^0$, which is exact. Since $\epsilon_j^0=0$, 
we have $\Delta_i^0 = \epsilon_i^0$.
%E
\item Estimate $\Delta_i^E$ as $\widehat{\Delta_i^E}=\widehat{\olep_i^E}-q_{ij} \widehat{\olep_j^E}=
\mean_k[\ln(1-\delta+2\delta\frac{\eta_i}{\eta_j}\beta_i^{\shp,(k)})]-\epsilon_i^0-
q_{ij} \mean_k[\ln(1-\delta+2\delta\beta_j^{(k)})]$, which has standard error 
$\se(\widehat{\Delta_i^E})=\sqrt{s_1^2+s_2^2}$, where $s_1=\sd_k[\ln(1-\delta+2\delta\frac{\eta_i}{\eta_j}\beta_i^{\shp,(k)})]/\sqrt{M}$
and $s_2=q_{ij}\sd_k[\ln(1-\delta+2\delta\beta_j^{(k)})]/\sqrt{M}$.
%C
\item Estimate $\Delta_i^C$ as $\widehat{\Delta_i^C}=\widehat{\olep_i^C}-q_{ij}\widehat{\olep_j^C}=
\mean_k[\ln(1-\delta+\frac{\delta}{2}\frac{\eta_i}{\eta_j}\frac{1}{\beta_j^{\shp,(k)}})]-\epsilon_i^0-q_{ij} 
\mean_k[\ln(1-\delta+\frac{\delta}{2}\frac{1}{\beta_j^{\shp,(k)}})]$, which has standard error
$\se(\widehat{\Delta_i^C})=\sd_k[\ln(1-\delta+\frac{\delta}{2}\frac{\eta_i}{\eta_j}\frac{1}{\beta_j^{\shp,(k)}})-
q_{ij}\ln(1-\delta+\frac{\delta}{2}\frac{1}{\beta_j^{\shp,(k)}})]/\sqrt{M}$.
%E#C
\item Estimate $\Delta_i^{(E\shp C)}$ as $\widehat{\Delta_i^{(E\shp C)}}=\widehat{\olep_i^{(E\shp C)}}-q_{ij}
\widehat{\olep_j^{(E\shp C)}}$. This has standard error 
$\se(\widehat{\Delta_i^{(E\shp C)}})=\sd_k[\ln(1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{\shp,(k)}}{\beta_j^{\shp,(k)}})-
\ln(1-\delta+2\delta\frac{\eta_i}{\eta_j}\beta_i^{\shp,(k)})-\ln(1-\delta+\frac{\delta}{2}\frac{\eta_1}{\eta_2}\frac{1}{\beta_j^{\shp,(k)}})-
q_{ij}\ln(1-\delta+\delta\frac{\beta_j^{(k)}}{\beta_j^{\shp,(k)}})+q_{ij}\ln(1-\delta+2\delta\beta_j^{(k)})+
q_{ij}\ln(1-\delta+\frac{\delta}{2}\frac{1}{\beta_j^{\shp,(k)}})]/\sqrt{M}$.
%E||C
\item Estimate $\Delta_i^{[E\nat C]}$ as $\widehat{\Delta_i^{[E\nat C]}}=\widehat{\olep_i^{[E\nat C]}}-
q_{ij}\widehat{\olep_j^{[E\nat C]}}=
\mean_k[\ln(1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{\nat,(k)}}{\beta_j^{\nat,(k)}})]-
\mean_k[\ln(1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{\shp,(k)}}{\beta_j^{\shp,(k)}})]+
q_{ij}\mean_k[\ln(1-\delta+\delta\frac{\beta_j^{(k)}}{\beta_j^{\shp,(k)}})]$, 
which has standard error
$\se(\widehat{\Delta_i^{[E\nat C]}})=\sd_k[\ln(1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{\nat,(k)}}{\beta_j^{\nat,(k)}})-
\ln(1-\delta+\delta\frac{\eta_i}{\eta_j}\frac{\beta_i^{\shp,(k)}}{\beta_j^{\shp,(k)}})+
q_{ij}\ln(1-\delta+\delta\frac{\beta_j^{(k)}}{\beta_j^{\shp,(k)}})]/\sqrt{M}$.
%[EC]
\item For $\Delta_i^{[EC]}$, we recall that $\olep_j^{[EC]}=0$, so $\Delta_i^{[EC]}=\olep_i^{[EC]}$.
So we use $\widehat{\olep_i^{[EC]}}$ for $\Delta_i^{[EC]}$.
%r
\item Finally, we can estimate $\olr_{i \bs i}-q_{ij} \olr_{j \bs i}$ simply as $\widehat{\olr_{i \bs i}}$,
since $\olr_{j \bs i}=0$.
\end{enumerate}

\section{Details of diatom model setup}\label{sect:diatom_model}

%The Q, K and V functions
Estimates of the temperature dependence functions $Q_i(t)$, $V_i(t)$, and $K_i(t)$, 
produced by earlier authors \citep{Descamps_2005,Ellner_2016,Ellner_2019} and which are part of the parameterization
of the diatom competition model described in the main text, are now described.
\cite{Descamps_2005} estimated values for $Q_i(t)$, $V_i(t)$, and $K_i(t)$ from 
single-species, nine-day batch experiments at four different temperatures ($6^\circ$C, 
$12^\circ$C, $18^\circ$C, $24^\circ$C) (see Table 1 of \citealp{Descamps_2005}) and 
used linear interpolations for the
functions $Q_i(t)$, $V_i(t)$, and $K_i(t)$. Their values and functions are 
pictured in Fig. \ref{fig:VKQ} using open circles and dashed lines.
\cite{Ellner_2016, Ellner_2019} used slightly modified values and functions,
pictured in Fig. \ref{fig:VKQ} by filled circles and solid lines. 
Our investigation follows \cite{Ellner_2016, Ellner_2019} and 
uses their modified functions.

%Defintions of E and C
Our decomposition of GWR is defined by the choices $E_i(t)=\theta(t)$, 
$C_{i}(t)=(K_i(t)+S(t))/S(t)$, which then imply $r_i(E_i,C_{i})=\frac{V_i(E_i)}{C_{i}} -D$. 
This choice follows one of the choices made in the R computer code provided by \cite{Ellner_2016} and 
\cite{Ellner_2019}.
Other choices are possible. For instance, in addition to this choice, 
\cite{Ellner_2016} also considers an alternative choice $E_i(t)=V_i(t)$,
as well as some other possibilities discussed in their supporting materials and 
represented in their computer code. 

%Outline how the quantities E_i and C_i\i were obtained from simulations. 
To obtain $E_i$ and $C_{i \bs i}$, the competition model was simulated for $T=3000$ time steps.
Environmental temperature fluctuations were defined by the paramters $a$, $P$, and $\theta_0$ using 
$\theta(t)=a\sin(2\pi t/P)+\theta_0$, and this determined $E_i(t)$ for $i=1,2$. To obtain 
$C_{i \bs i}$, a simulation was carried out starting from $x_i=0$ and $x_j=20$.
Dilution was set to $D=0.09$ and inflow silicate concentration was set at $S_0=35$. A burn in time 
of $\frac{2}{3}T$ was cut from the simulation and the $S(t)$ time series from the remainder of the simulation,
along with $K_i(t)=K_i(\theta(t))$ were plugged in to the expression $C_{i}(t)=(K_i(t)+S(t))/S(t)$. 

\section{     Decomposing storage effects in the diatom case study}\label{sect:Empircal_app}

The decomposition of storage effects and quantification of contributions of ATAs depends on 
removing asymmetric tail associations from the bivariate random variable
$(E_i,C_{i \bs i})$, while maintaining its correlation and marginal distributions, to produce a new
random variable $(E_i^\nat,C_{i \bs i}^\nat)$.
In the Theory section of the main text, we decribed this removal process
when the distributions of $E_i$ and $C_{i \bs i}$ are known exactly, but for the 
diatom example, 
we only had samples from $(E_i,C_{i \bs i})$, based on simulations. We here describe how to
produce a sample from $(E_i^\nat,C_{i \bs i}^\nat)$ in this modified context. 
Let $(E_{i,k},C_{i \bs i,k})$, $k=1,\ldots,T$ denote the samples from $(E_i,C_{i \bs i})$.
Let $\rk(E_{i,k})$ be the rank of $E_{i,k}$ in the set 
of $E_{i,k}$, $k=1,\ldots,T$, where the smallest value has rank $1$. Likewise 
define $\rk(C_{i \bs i,k})$ as the rank of $C_{i \bs i,k}$ in the set
of $C_{i \bs i,k}$, $k=1,\ldots,T$. Define the ``normalized rank''
$\nrk(E_{i,k})$ as $\rk(E_{i,k})/(T+1)$, and likewise define 
$\nrk(C_{i \bs i,k})$ as $\rk(C_{i \bs i,k})/(T+1)$. Letting $\varphi$ be the CDF
of a standard normal distribution, the samples $\varphi^{-1}(\nrk(E_{i,k}))$, $k=1,\ldots,T$
are standard normally distributed, as are the samples 
$\varphi^{-1}(\nrk(C_{i \bs i,k}))$, $k=1,\ldots,T$. Let $\rho_i$ be the covariance 
of these samples. We then define a bivariate normal random variable 
$(e_i,c_{i \bs i})$ such that $\E(e_i)=\E(c_{i \bs i})=0$, $\var(e_i)=\var(c_{i \bs i})=1$,
and we denote $\cov(e_i,c_{i \bs i})$ by $\ddot{\rho}_i$. We used $\ddot{\rho}_i = \rho_i$.
Generating a sample $(e_{i,k},c_{i \bs i,k})$, $k=1,\ldots,T$ from this distribution,
we permute the ordered set $(E_{i,1},E_{i,2},\ldots,E_{i,T})$ so that the ranks of the 
permuted ordered set equal the ranks of the corresponding elements of the ordered
set $(e_{i,1},e_{i,2},\ldots,e_{i,T})$. We likewise permute the ordered set 
$(C_{i \bs i,1},C_{i \bs i,2},\ldots,C_{i \bs i,T})$ so the ranks of the permuted result
match the ranks of $(c_{i \bs i,1},c_{i \bs i,2},\ldots,c_{i \bs i,T})$.
This step works as long as there are no ties among the $E_{i,k}$ or among
the $C_{i \bs i,k}$. There were no ties when we applied these methods to the diatom system. 
The two permuted ordered sets, here denoted $(E_{i,1}^\nat,E_{i,2}^\nat,\ldots,E_{i,T}^\nat)$
and $(C_{i \bs i,1}^\nat,C_{i \bs i,2}^\nat,\ldots,C_{i \bs i,T}^\nat)$,
when combined to make ordered pairs, form the desired sample from 
$(E_i^\nat,C_{i \bs i}^\nat)$. Because $(E_{i,1}^\nat,\ldots,E_{i,T}^\nat)$
is a permutation of $(E_{i,1},\ldots,E_{i,T})$ and 
$(C_{i \bs i,1}^\nat,\ldots,C_{i \bs i,T}^\nat)$ is a permutation of
$(C_{i \bs i,1},\ldots,C_{i \bs i,T})$, marginal distributions of our
sample from $(E_i^\nat,C_{i \bs i}^\nat)$ were the same as those of our original 
sample from $(E_i, C_{i \bs i})$. The choice of bivariate normal
$(e_i,c_{i \bs i})$ ensures that our resulting sample shows symmetric tail association.
Finally, we caution that sampling variation means any quantity computed from our resulting sample 
$(E_{i,k}^\nat,C_{i \bs i,k}^\nat)$, $k=1,\ldots,T$ should be recomputed for 
multiple such samples, all computed via the same process, and a median of 
the resulting distribution of values should be used.

\section{   Asymmetric associations between population vital rates}\label{sect:vital_rates}

Whereas the ``$E$'' of ``$EC$-covariance'' is often conceptualized as ``environment'', 
in fact it is often instead a 
species response to the environment. Because a directly measurable aspect of the 
environment and a species response to it may be nonlinearly related, it may be 
important, in future work, 
to also study the nature of tail associations between species vital rates.
In the lottery model, it was assumed that fecundity of species $i$ tracks the
environment directly, $B_i(t)=E_i(t)$. But vital rates such as fecundity are 
more likely related to commonly measured environmental variables according to a nonlinear
function which may often be threshold-like or sigmoidal, and thus the $E_i=B_i$
of the lottery model is probably better conceptualized as a species response.
Likewise, one of the choices of $E_i$ considered by \cite{Ellner_2016} for the
diatom model was $E_i=V_i$, the maximum population growth rate, a response
to the environment rather than a direct environmental measurement. 
It was demonstrated elsewhere that nonlinear transformations can produce or alter 
asymmetries of tail association \citep{Ghosh_2020_AER,Walter_2022}.
So the nature of ATAs between directly measured environmental variables may differ from the
nature of ATAs between the population responses which matter for coexistence.
Vital rates are measured directly in demographic studies, so ATAs between vital rates could,
in principle, be studied. To our knowledge, this has not been done. 

\section{    Three-way decompositions}\label{sect:threeway}

\cite{Ellner_2019} elaborated a general theory in which more and different varying factors than
$E$ and $C$ can be considered and used to produce a decomposition of GWR. For instance, if $X$, $Y$ and 
$Z$ are temporally varying factors, \cite{Ellner_2019} produced, for the $i^{\text{th}}$ species, a decomposition
of the GWR of $i$ for which some terms were based on rendering one or 
more of $X$, $Y$, and $Z$ independent of the others. 
We comment that this general decomposition should also be extendable to consider the effects of
ATAs in the same way (\ref{eq:full_decomp}) extends (\ref{eq:previous_decomp}). Details follow.

As mentioned in the Discussion in the main text, \cite{Ellner_2019} elaborated 
a general theory in which more and different varying factors than
$E$ and $C$ can be considered and used to produce a decomposition of GWR. For instance, if $X$, $Y$ and 
$Z$ are temporally varying factors, \cite{Ellner_2019} produced, for the $i^{\text{th}}$ species, the decomposition
\begin{align}
\text{GWR}_i &= \Delta_i^0+\Delta_i^X+\Delta_i^Y+\Delta_i^Z \label{eq:9}\\
&+\Delta_i^{(X \shp Y)} +\Delta_i^{(XY)} + \Delta_i^{(Y \shp Z)} + \Delta_i^{(YZ)} +\Delta_i^{(X \shp Z)}+\Delta_i^{(XZ)} \label{eq:10}\\
&+ \Delta_i^{(XYZ)}+\Delta_i^{(XY \shp Z)}+\Delta_i^{(X \shp YZ)}+\Delta_i^{(XZ \shp Y)}+\Delta_i^{(X \shp Y \shp Z)}.\label{eq:11}
\end{align}
The terms in (\ref{eq:9}) and (\ref{eq:10}) are analogous to those of main text equations (\ref{MT-eq:previous_decomp}).
The new terms in (\ref{eq:11}) result from rendering one or 
more of $X$, $Y$, and $Z$ independent of the others.
We simply comment that this general decomposition should also be extendable to consider the effects of
ATAs in the same way main text equation (\ref{MT-eq:full_decomp}) extends main text equation (\ref{MT-eq:previous_decomp}), 
though the complexity
of such a decomposition may present challenges.
For example, $\Delta^{(XY \shp Z)}$ can be decomposed as $\Delta^{[XY \shp Z]} + \Delta^{[X \nat Y \shp Z]}$.

\clearpage
\newpage

%***DAN: This looks pretty good except one of the histograms on c does not look like the plotted
%pdfs of the marginals. I think Jasmin said in an email she was fixing this.
%***DAN: Jasmin, also, we use \varphi in the text, but \phi here. These need to be made consistent, since they are different to
%a math person. The easiest way will be to change it in the figure, so I hope that can straightforwardly be done.
\begin{figure}
\includegraphics[width=1.025\textwidth]{../results_figs/theory_fig_col.pdf}
\caption[Visual guide to removing asymmetries of association]{Illustration of how asymmetric tail associations are removed while retaining marginal distributions and correlation 
between variables (see Theory). (a) An example original bivariate distribution $(E_i,C_{i \bs i})$, with ATA present. 
(b) Marginals are now normalized. The variables $E_i$ and $C_{i \bs i}$ are individually transformed to have standard normal 
marginals through a composition of the inverse of the standard normal cumulative distribution function (CDF), 
$\varphi^{-1}$, and 
each variable's CDF, $F_{E_i}$ and $F_{C_{i \bs i}}$, respectively.  
(c) A newly generated bivariate normal distribution, $(e_i,c_{i \bs i})$, with correlation $\ddot{\rho}=\rho$
selected to match that of the original distribution (see Theory). (d) Two new variables, 
$E_i^{||}$ and  $C_{i \bs i}^{||}$,
%Dan replaced \nat in the above two expressions by || because for some reason the \nat does not
%compile when it occurs within a caption. Not sure how to deal with that, but leaving it alone for now.
which have the same marginals and correlation as the original $E_i$ and $C_{i \bs i}$ variables of (a) but 
which have symmetric association structure. These variables are obtained by transforming the marginals from (c), 
$e_i$ and $c_{i \bs i}$, using the inverses of the functions used in (b).
For illustration purposes we started with beta distributed $E_i$ and $C_{i \bs i}$. Contour lines are 
$\log_{10}$ of probability density on all panels. 
\label{fig:pedagog2}}
\end{figure}

\clearpage
\newpage

\begin{figure}
\includegraphics[width=\textwidth]{../results_figs/decompFigLLNqij.pdf}
\caption[Analogous to Fig. \ref{MT-fig:fig3} but making a different choice for $q_{ij}$]
{Analogous to Fig. \ref{MT-fig:fig3} of the main text, but using 
$q_{ij}=\exp(\mu_i)/[(1-\delta)\exp(\mu_j)+\delta\exp(\mu_i)]$. See the caption of
that figure for details. Standard errors of plotted quantities 
were never greater than \Sexpr{round(se3qij,5)}, so are not displayed.}\label{fig:fig3_alt}
\end{figure}

\clearpage
\newpage

\begin{figure}
\includegraphics[width=\textwidth]{../results_figs/decompFigLBqij.pdf}
\caption[Analogous to Fig. \ref{MT-fig:fig4} but making a different choice for $q_{ij}$]
{Analogous to Fig. \ref{MT-fig:fig4} of the main text, but using 
$q_{ij}=\eta_i/(\eta_j(1-\delta)+\eta_i \delta)$. See the caption of
that figure for details. Standard errors of plotted quantities 
were never greater than \Sexpr{round(se4qij,5)}, so are not displayed.}\label{fig:fig4_alt}
\end{figure}
%***DAN: Jasmin, the value of se4 quoted in the main text was the same, to 5 digits, as the 
%value of se4qij quoted here. This made me suspicious so I checked the values to 9 digits
%and they were the same to 9 digits. This seems like it must be an error in the code. Please
%check. The standard error expressions in SI S5.2 DO depend on qij, so this seems like it
%should not happen. The standard errors listed in Fig. 3 and Fig. S1 are different, so that's
%good.
%JASMIN: I think its okay that they are the same.

\clearpage
\newpage

\begin{figure}
\includegraphics[width=.66\textwidth]{../results_figs/VKQfig.pdf}
\caption[Maximum growth rate, cellular silicate content, and half sturation constant dependences on temperature.]
{Species maximum population growth rates, $V_i$ (a), half saturation constants for the dependence 
of growth rates on nutrient concentration, $K_i$ (b), and cellular silicate content, $Q_i$ (c) dependend on 
temperature in ways explored by \cite{Descamps_2005} and \cite{Ellner_2016, Ellner_2019} and 
pictured here. Species 1 is \emph{F. crotonensis}, shown in blue, and species 2 is 
\emph{C. pseudostelligera}, shown in red. Open circles and dashed lines indicate estimated 
values and interpolations from \cite{Descamps_2005} and closed circles and solid lines indicate 
values and functions used by \cite{Ellner_2016, Ellner_2019} and in our analyses. The two sets of
estimates and functions coincide on (c), except for the right-most point for species 2. For that species,
data were not available for $Q$ at $24^\circ$C from the original study of \cite{Descamps_2005}; \cite{Ellner_2016, Ellner_2019}
assumed constancy of $Q_2$ for temperature between $18^\circ$C and $24^\circ$C. Data were also not avaialable at
$24^\circ$C for $K_2$, and \cite{Ellner_2016, Ellner_2019} assumed constancy of $K_2$ for teperatures from 
$12^\circ$C through $24^\circ$C. \label{fig:VKQ}}
\end{figure}

%\begin{figure}
%\includegraphics[width=\textwidth]{../results_figs/fig5_2.pdf}
%\caption[Analogous to Fig. \ref{MT-fig:fig5} but reverse invader-resident scenario.]
%{Analogous to Fig. \ref{MT-fig:fig5} but \emph{C. pseudostelligera} is the invader and 
%\emph{F. crotonensis} is the resident. See the caption of
%that figure for details. Standard errors..\label{fig:fig5_2}}
%\end{figure}

%\begin{figure}
%\includegraphics[width=.38\textwidth]{../results_figs/fig6_2.pdf}
%\caption[Analogous to Fig. \ref{MT-fig:fig6} but reverse invader-resident scenario.]
%{Analogous to Fig. \ref{MT-fig:fig6} but \emph{C. pseudostelligera} is the invader and 
%\emph{F. crotonensis} is the resident. See the caption of
%that figure for details. Standard errors..\label{fig:fig6_2}}
%\end{figure}

\clearpage
\newpage

%you store your bibliographic info in refs.bib, see that file
\bibliographystyle{ecology_letters2}
\bibliography{refs}

\end{document}